# GARAGE

This folder contains code to run RL experiments on the environments of the paper and replicate the results therein.

## Requirements:

Installation requires a mujoco key. See [here](https://www.roboti.us/license.html) for instructions on how to acquire one. This repository has not been tested on a computer without a cuda-enabled GPU or one that isn't running an Ubuntu OS. Install on such a machine at your own risk.

## Installation:

To install, execute in a cli `bash scripts/setup_linux.sh --mjkey=<path-to-mjkey` where `<path-to-mjkey>` is replaced with the absolute path to `mjkey.txt`. If you want to install without MuJoCo, comment out all the related lines in `script/setup_linux.sh`.

## Usage:

### Vanilla TRPO/DDPG:

	To reproduce the vanilla RL experiments, simply execute the relevant python file in the `examples` folder, e.g. `pendulum_trpo` to reproduce the pendulum experiment with TRPO. Set the `exp_id` variable to a value of your choice between 1 and 10 (this selects the random seed).

### Supervised Learning:

	To train a policy to imitate a set of trajectories, execute `python garage/envs/supervised.py`. Set the `src` variable to the filepath of a pickled (.pkl) object that has a 'policy' entry that is of one of the classes defined in `garage/tf/policies` (hint: running a vanilla experiment will generate such a file). Set the `dest` variable to a filepath where you want to get the resulting policy. Set the `data_filepath` variable to the filepath of a .npz file containing entries 'obs' for state observations and 'act' for actions.

### P2D2:

	After using the supervised learning procedure to train a policy on the trajectories generated by R3L exploration, execute the relevant python file in the `examples` folder. Set the `init_filepath` variable to the .pkl file containing the pre-trained policy.

